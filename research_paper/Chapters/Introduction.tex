\chapter{Introduction} \label{chap:one}
This research paper aims to present a methodology for evaluating how well modern AV implementations can participate in realistic traffic scenarios and get from one location to another safely.

The fundamental obstacle that science and major car manufacturers need to overcome to set up the widespread recognition of autonomous vehicles is establishing trust in the AVs and assuring that they can be a safer and more convenient means of transportation. This is is well presented in the available literature considering autonomous vehicles \cite{choi2015investigating}.

However, according to the 2022 survey carried out by Policygenius in the  U.S. \cite{policy_genius}, 76\% of respondents said that they would feel less safe driving in cars with self-driving features, while a similar proportion (73\%) said they would feel less safe knowing others are driving on the road in autonomous vehicles. This shows that although people have been restless for decades trying to establish general acceptance of technology that will massively alter how we see and use transportation today, they have not succeeded yet.

One thing that could change this perception is autonomous vehicles appearing on the streets and demonstrating that statistically, they can be better vehicle operators than human drivers. However, the law that we live by today does not allow autonomous vehicles to navigate the streets freely because there is a lack of standards and regulations for it, and it is not defined who has to be responsible if a machine makes a mistake. The recently emerged branch of AI, the XAI, promises to take this a step forward, providing the machine with the ability to explain its actions. This is particularly relevant in situations where an AV gets involved in an accident, and it is crucial to understand the circumstances that led to this and what were the vehicle operators doing to prevent this or at least minimise the impact.

An alternative that is available today is demonstrating the AI potential in a virtual, simulated world where there is no law preventing autonomous vehicles from driving on the streets and no living being able to get hurt. This article focuses on creating a framework that would allow testing the AV implementations in such a virtual setting and analysing the observations, thus determining whether the AI agent is acting safely and, if not, where the issues lie.

We start by exploring the concept of autonomous vehicles, how safe they could be and what vulnerabilities they might have if they are finally put on the streets. In \autoref{chap:three}, we continue our journey by analysing the road statistics in Europe and the U.S. from 2021 until 2022 and discussing how the scenario generation algorithm could be designed based on the observations. Subsections of the chapter mentioned above also analyse human behaviour in driving situations and discuss the relevance of statistics to this project. In \autoref{chap:four}, we discuss the chosen simulator CARLA, its advantages and shortcomings, and explain its role in the research while also covering details of how different AV implementations could be used with the simulator. In \autoref{chap:five}, we finally arrive at the scenario generation tool, one of the three main framework components. This part covers the tool's development process and inner workings while also emphasising the importance of road statistics and traffic data for its development. The following \autoref{chap:six}, dives into detail about how safety can be measured in the simulation environment, what tools are needed for that and describes in detail the safety measuring system this article is proposing that can determine how safe the vehicles are performing in the simulated scenarios. This section also provides an overview of what safety metrics are evaluated and proposes a formula to assess the performance. In \autoref{chap:seven}, we introduce the data analysis tool, the last of the three main software components. We talk in detail about how it can be used to both analyse the performance scores of the participated agents and group interesting clusters of information obtained from the sensors and simulation recordings. After introducing the main software components, in \autoref{chap:eight} we will swiftly look at how the system functions as a whole and how all the modules work together. \autoref{chap:nine} focuses on evaluating how well the system functions by looking at the research involving human participants and a CARLA agent driving the generated scenarios. The chapter looks at the safety monitoring system in action and applies the data analysis tools to assess participant performance. It also compares how well the CARLA autonomous agent is executing the given scenarios compared to human participants.

The article ends in \autoref{chap:ten}, having presented a working framework that generates diverse driving scenarios based on real-life data, allows human drivers and AI agents to drive in the scenarios and measures their safety performance. This last chapter overviews what has been achieved and what could be improved. It discusses the relevance of this work and why the chosen subject is so impactful. In addition, it talks about the ethical questions concerning the project and the field of autonomous driving as a whole. The last section of the article provides a short self-reflection of the author about the challenges faced throughout the project's development.